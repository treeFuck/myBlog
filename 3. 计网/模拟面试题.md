# 模拟面试题

## 四、 计网

### 说一下 OSI 模型
从上到下是：
1. 应用层，网络服务和用户的接口，比如 http、dns
2. 表示层，数据的表示、安全、压缩，比如 ASCII 格式
3. 会话层，建立、管理、终止会话，对应主机进程，指本地主机与远程主机正在进行的会话
4. 传输层，比如 TCP、UDP 协议
5. 网络层，比如 IP 协议
6. 数据链路层，用 MAC 地址访问接制
7. 物理层

传统的五层协议的话，是将表示层、会话层都归属到了应用层。

TCP/IP 四层模型是：
1. 应用层
2. 传输层
3. 网络层
4. 网络接口层

### 说一下 TCP 和 UDP 的区别
UDP 特点:
1. 无连接
2. 尽最大努力交付
3. 没有拥塞控制
4. 面向报文
5. 支持一对一、一对多、多对一和多对多

TCP 特点：
1. 面向连接
2. 提供可靠交付
3. 有流量控制、拥塞控制、提供全双工通信
4. 面向字节流
5. 每一条 TCP 连接都是点对点（一对一）

所以说白了，它们最大的区别就是， UDP 把报文发出去就不管了，但 TCP 的话会连接一条通道，通过超时重传机制来保证这份报文一定要发送到对方那里，也因此 TCP 要维护滑动窗口、计时器、缓存……，对于资源的消耗会比 UDP 大。

### 说一下运输层的复用和分用
复用：多个应用层的进程，使用同一个运输层的服务
分用：运输层从网络层收到报文，会分发到对应的应用层进程

### 说一下 TCP 可靠传输
可靠传输，说白了就是我要保证发送方的每一份报文都能到达接收方。具体一点就是，超时重传，我发送了一份报文过去，等过一段时间没有收到对应对这份报文的确认，那么我就认为这份报文是没有抵达接收方的。

可靠传输有那么几个协议：
1. 停止等待协议。发送一个报文后，要等收到这份报文的确认之后，我再发送下一份报文，如果等待超时了就重发。这种协议最大的缺点是，信道利用率低。
2. ARQ 协议。发送方维护一个发送窗口，在发送窗口里的分组都可以连续发送出去，而不需要等待确认。接收方呢，只需要对按序抵达的最后一个分组发送确认，不过这样有一个缺点，就是比如我发 5 个分组，只有第 2 个没到，但接收方之后返回第一个分组的确认，所以发送方要重发后面 4 个分组，其中有 3 个分组是没必要在发送的。
3. 滑动窗口协议。在发送方维护一个发送窗口，接收方维护一个接收窗口，发送窗口的大小由接收方指定并以此来进行流量控制。另外，可以通过选择确认 SACK 来避免 ARQ 协议的缺点，简单点说就是用多个位来表示不连续缺少的分组。

### 说一下 TCP 流量控制
所谓流量控制，就是让发送方的发送速率不要太快，要让接收方来得及接收。
TCP 通过滑动窗口协议的来实现流量控制。

滑动窗口：
1. 在发送方和接收方都维护一个窗口，窗口的单位是字节。
2. 发送报文的时候，就把发送窗口里的分组连续发送出去。接收窗口收到分组后，拿到最后一位有序的分组，并向前移动接受窗口，最后给有序到达分组的最后一位返回确认，附带表示接收窗口 rwnd 大小的值：
	1. 分组确认是用来让发送窗口向前移动的，以便发送新的分组
	2. 接收窗口 rwnd 是用来控制发送窗口大小的，以便进行流量控制

### 说一下 TCP 的发送缓存和接受缓存
发送缓存组成（左到右）：
1. 已发起且收到确认的分组
2. 已发送但未收到确认的分组（发送窗口左端）
3. 待发送分组（发送窗口右端）
4. 未发送分组

接收缓存组成（左到右）：
1. 已到达但未分发的分组
2. 未到达的分组（接收窗口左端）
3. 未按序到达的分组（接收窗口内部）

![](./img/TCP缓存和滑动窗口.jfif)

### 说一下 TCP 拥塞控制
如果网络出现拥塞，分组将会丢失，此时发送方如果继续重传，会让网络更加拥塞。所以需要一个拥塞控制的机制，去降低整个网络的拥塞程度。

发送方需要维护一个叫拥塞窗口（cwnd）的状态变量，以此去影响发送窗口的大小。
> 实际发送窗口 = min ( 拥塞窗口 cwnd，接收窗口 rwnd )

### 说一下 TCP 拥塞控制使用到的算法
TCP 的拥塞控制主要通过四个算法：慢开始、拥塞避免、快重传、快恢复。

慢开始和拥塞避免：
> 慢开始，就是让拥塞窗口从 1 开始，所以只发生一个分组，当收到分组确认，再把拥塞窗口加倍以发送更多分组。
>
> 拥塞避免呢，就是给慢开始设定一个门槛 ssthresh ，当拥塞窗口到达某个限制后，就不是加倍递增，而是加一递增。
> 
> 如果出现超时，则把拥塞避免的限制 ssthresh 减半，重新执行慢开始

快重传和快恢复：
> 快重传，就是发送方如果收到三个对相同分组的确认，那么立即对收到重复确认分组的下一段分组进行重传。
> 
> 快恢复，就是对于快重传这种情况，只是丢失部分报文段，而不属于网络拥塞。因为进行快恢复，令 令 ssthresh = cwnd / 2 ，cwnd = ssthresh，即直接进入到拥塞避免阶段。

### 说一下 TCP 拥塞控制和流量控制的不同
出发点不同：
1. 流量控制是控制发送方发送分组的速率，以便接收方能来得及接收。
2. 拥塞控制关注点是整个网络，是为了降低整个网络的拥塞程度


### 说一下 TCP 三次握手
1. 第一次握手：客户端发送一个 SYN=1，ACK = 0 的报文给服务端，表示请求建立连接
2. 第二次握手：如果服务端收到第一次握手的请求报文后，如果同意建立连接，返回一个 SYN=1，ACK=1 的响应报文
3. 第三次握手：客户端收到服务端的响应报文，还需要再给服务端发送一个 ACK=1 的确认报文。

第三次握手的目的，是为了防止已经失效的请求再次抵达服务端而产生错误。一个失效的连接请求发送到服务端，服务端依旧会返回一个确认给客户端。但因为这是一个失效请求的确认，所以客户端会无视它，不会发起第三次握手。服务端没有收到第三次握手，就明白刚刚的请求是失效的，不会建立连接。
### 说一下 TCP 四次挥手
1. 第一次握手：客户端发送一个 FIN=1 的报文，表示断开连接
2. 第二次握手：服务端收到客户端第一次挥手报文后，返回客户端一个确认，表示自己已经收到了请求，但是它还没准备好，可能还有一些其他的请求没处理完毕。
3. 第三次握手：服务端准备好断开连接了，就给客户端发送一个 FIN=1 的报文，表示断开连接
4. 第四次握手：客户端收到第三次握手的报文后，给服务端发送一个确认报文。服务端收到确认报文后，就可以释放连接了，但是客户端还需要等待 2MSL 的时间才断开连接。等待 2MSL 的目的是，确保第四次握手成功发送到服务端，以及处理服务端可能的对“已失效连接请求”的确认返回。

### 说一下 HTTP/1.1 和 HTTP/2.0 的区别
1. HTTP/2.0 的多路复用：
	- HTTP/1.1是串行共享一个 TCP 连接，上一个请求结束了，下一个的请求才会发起
	- HTTP/2.0 实行并行策略，多个请求可同时在一个 TCP 连接上并行执行，也叫多路复用
2. 数据流格式不一样：
	- HTTP/1.1 使用的是文本流
	- HTTP/2.0 使用的是二进制分帧，服务器解析起来会更快
3. 首部压缩
	- HTTP/1.1 首部不会压缩，每一次请求都需要发送一个新的首部
	- HTTP/2.0 在客户端和服务端之间维护一个首部字段表，这个首部字段表会包含之前出现过的首部字段，每次发起请求只会发送要更新的首部字段。另外，还使用了编码算法对首部进行压缩
4. 服务端推送
	- HTTP/1.1 不支持服务端推送
	- HTTP/2.0 支持服务端推送

### 说一下 HTTPS
HTTP 有三个缺点：
1. 明文传输 → 内容可能被窃听
2. 不验证通信双方 → 通信方可以伪造
3. 不验证报文完整性 → 报文可能被篡改

所以，提出了 HTTPS。

1. 加密：加密方式有两种，共享密钥加密和公开密钥加密。HTTPS 采取两者混合方式进行通信内容的加密。首先，通信双方先通过公钥加密传递一把共享密钥，然后后续的通信用这边共享密钥进行通信。
2. 验证通信双方：服务端的公钥需要提交给第三方权威机构进行认证，第三方机构会给公钥颁发证书，证书上有一个数字签名，这个签名用第三方机构私钥加密。服务端在给客户端发送公钥的时候把证书也发过去，客户端本地拥有第三方机构的公钥，可以认证证书上的数字签名的真实性，进而认同证书的权威性，也就相信了发送公钥的服务端。这个是客户端认证服务端。也存在客户端证书让服务端认证客户端，但是比较少，加格也昂贵。
3. 验证报文完整性：通过报文摘要来验证报文完整性。HTTP 也报文摘要，但因为它是明文传输，所以报文摘要也很容易进行篡改。HTTPS 因为加密导致报文摘要的成功篡改比较困难，进而可以保证报文完整性。

优点：能解决 HTTP 的三大缺点
缺点：因为需要对通信内容进行加密和解密，传输速度比 HTTP 慢；需要购买证书，需要一定成本。
		

### 说一下跨域
首先，跨域是什么？
跨域是因为浏览器的同源策略，导致 AJax 无法对非同源的资源进行请求。
同源的意思是：相同协议+相同域名+相同端口

然后，怎么解决？
第一，JSONP。
创建一个 script 标签插入文档，script 不受同源策略限制，会对它的 src 发起 get 请求，然后将响应数据传入指定的回调函数，我们从那个回调函数里获取 JSONP 跨域请求的响应。
优点是简单，而且不需要服务端做出修改。
缺点是只能发起 get 的跨域请求。

第二，CORS。
CORS 也叫跨域资源共享。一般是客户端发起请求的时候，在首部 Origin 字段告诉服务器自己的源，服务器判断该请求源是否在自己的允许跨域白名单里，如果在的话就同意跨域返回响应。另外对于一些特殊请求，比如发送 json 数据的 post 请求，浏览器会先发送一个 option 预检请求。

优点是：能够解决全部请求类型的跨域问题。
缺点是：不兼容一些较老的浏览器，而且需要服务端配置

第三，代理服务器
在本地搭建一个与页面同源的代理服务器，页面向代理服务器发送请求，代理服务器向真实服务器转发请求。常见的有 nodejs 代理服务器和 nginx 反向代理。

优点是：不需要服务端修改
缺点是：代理服务器搭建麻烦，不过可以结合一下脚手架工具来简化搭建工作

### ARP 解析 MAC 地址


### DNS 解析域名


### CND + OSS 加速原理
1. CDN 内容分发网络，就是把源站资源缓存到多个边缘节点，然后当客户端对源站发起请求时，会把请求引导到距离客户端最近的边缘节点上，一方面距离更短资源访问速度肯定更快，另一方面可以分摊源站的访问请求压力。
2. OSS 阿里云对象存储，使用它作为 CDN 的源站的话，可以利用其更大的带宽和更大的存储，用来实现对客户端对大文件资源的快速访问。